# GRU Text Generation

This project uses a Gated Recurrent Unit (GRU) neural network for text generation. GRUs are a type of recurrent neural network (RNN) that can capture dependencies across sequences, making them ideal for tasks like text generation.

## Table of Contents

- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

## Introduction

Gated Recurrent Units (GRUs) are a type of RNN designed to capture long-term dependencies in sequential data. This project demonstrates how to build and train a GRU model to generate text based on a given dataset.

## Installation

1. Clone the repository:

```bash
https://github.com/Nishant2018/GRU-Scratch-.git
cd gru-text-generation
